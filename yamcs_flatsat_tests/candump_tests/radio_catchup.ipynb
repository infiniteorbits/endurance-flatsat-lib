{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from candump_utils.can_id import write_candump_line\n",
    "from candump_utils.packet_header import process_first_message_data\n",
    "from candump_utils.data_field_tm import process_data_field_tm\n",
    "from candump_utils.data_field_tc import process_data_field_tc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Librairies and Dictionnaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Test Message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message = [\"can0  00110400   [8]  00001111 00000111 00000000 00000010 11000000 00001010 00011000 00000001\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_big_to_little_endian(bit_message: str) -> str:\n",
    "    \"\"\"\n",
    "    Converts a bit message from big-endian to little-endian format.\n",
    "\n",
    "    Args:\n",
    "        bit_message (str): A string of bits separated by spaces, representing octets in big-endian order.\n",
    "\n",
    "    Returns:\n",
    "        str: The bit message converted to little-endian format, with spaces between octets.\n",
    "    \"\"\"\n",
    "    # Split the input message into a list of 8-bit groups (octets)\n",
    "    octets: list[str] = bit_message.strip().split()\n",
    "\n",
    "    # Validate that each octet is exactly 8 bits and contains only '0' or '1'\n",
    "    if not all(len(octet) == 8 and set(octet).issubset({\"0\", \"1\"}) for octet in octets):\n",
    "        raise ValueError(\"Input must be a space-separated string of valid 8-bit binary numbers.\")\n",
    "\n",
    "    # Reverse the order of the octets for little-endian format\n",
    "    reversed_octets: list[str] = octets[::-1]\n",
    "\n",
    "    # Join the reversed octets with spaces\n",
    "    return \" \".join(reversed_octets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Decode CAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpt = 0\n",
    "\n",
    "for line in message:\n",
    "    print(\"#-----------------------------------------------------------#\")\n",
    "    print(line)\n",
    "\n",
    "    # Call write_candump_line for each line\n",
    "    can_id, supervisor = write_candump_line(line)\n",
    "    sbr = can_id[\"sbr_type\"]\n",
    "\n",
    "    if supervisor:\n",
    "        print(\"/**-------------------------SUPERVISOR-------------------------**/\")\n",
    "        continue\n",
    "\n",
    "    # For the first line, process the first message and get the length\n",
    "    if (sbr == \"Set Block Request\") & (can_id[\"sb_type\"] != \"Unsolicited Telemetry\"):\n",
    "        x, _ = write_candump_line(line, doplot=False)\n",
    "        nb_blocks = int(x[\"block_to_transfert\"])\n",
    "\n",
    "        packet_header = process_first_message_data(line)\n",
    "        tmtc = packet_header[\"str_type\"]\n",
    "\n",
    "    # For the second line, process the TM data field\n",
    "    elif sbr == \"Transfer\":\n",
    "        if tmtc == \"TM\":\n",
    "            if cpt == 0:\n",
    "                process_data_field_tm(line)\n",
    "                cpt += 1\n",
    "        elif tmtc == \"TC\":\n",
    "            if cpt == 0:\n",
    "                process_data_field_tc(line)\n",
    "                cpt += 1\n",
    "        else:\n",
    "            raise ValueError\n",
    "    else:\n",
    "        cpt = 0\n",
    "\n",
    "    print(\"#-----------------------------------------------------------#\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_first_message_data(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = line.split(None, 3)[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_big_to_little_endian(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_first_message_data(convert_big_to_little_endian(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cparameters(ccf_type: int = 0, ccf_stype: int = 0) -> Optional[list]:\n",
    "    \"\"\"\n",
    "    Retrieve the CCF_CNAME based on CCF_TYPE and CCF_STYPE from a CSV file.\n",
    "\n",
    "    Args:\n",
    "    dat_file (str): The path to the CSV file containing the data.\n",
    "    ccf_type (int): The type to search for.\n",
    "    ccf_stype (int): The subtype to search for.\n",
    "\n",
    "    Returns:\n",
    "    str: The CCF_CNAME if a match is found, otherwise an empty string.\n",
    "    \"\"\"\n",
    "\n",
    "    name = get_cname(ccf_type, ccf_stype)\n",
    "\n",
    "    config = read_config({\"Submodule\": [\"name\", \"commit\"]})\n",
    "    expected_commit = config[\"Submodule.commit\"]\n",
    "    dat_file = f\"cdf_table_{expected_commit}.dat\"\n",
    "\n",
    "    # Lire le fichier CSV dans un DataFrame\n",
    "    path_df = os.path.join(get_project_root(), \"etc/config/\", dat_file)\n",
    "    df = pd.read_csv(path_df, sep=\"\\t\")\n",
    "\n",
    "    # Filtrer les résultats en fonction de CCF_TYPE et CCF_STYPE\n",
    "    result = df[(df[\"CDF_CNAME\"] == name)]\n",
    "\n",
    "    if result.value_counts().count() == 0:\n",
    "        return None\n",
    "\n",
    "    return list(result.CDF_PNAME.to_dict().values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = get_cparameters(20, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = get_cname(17, 1)\n",
    "\n",
    "\n",
    "config = read_config({\"Submodule\": [\"name\", \"commit\"]})\n",
    "expected_commit = config[\"Submodule.commit\"]\n",
    "dat_file = f\"cdf_table_{expected_commit}.dat\"\n",
    "\n",
    "# Lire le fichier CSV dans un DataFrame\n",
    "path_df = os.path.join(get_project_root(), \"etc/config/\", dat_file)\n",
    "df = pd.read_csv(path_df, sep=\"\\t\")\n",
    "\n",
    "# Filtrer les résultats en fonction de CCF_TYPE et CCF_STYPE\n",
    "result = df[(df[\"CDF_CNAME\"] == name)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.value_counts().count() == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
